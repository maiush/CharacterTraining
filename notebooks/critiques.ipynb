{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from charactertraining.constants import DATA_PATH\n",
    "from charactertraining.questions import TRAITS\n",
    "from charactertraining.claude_questions import CLAUDE_TRAITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = pd.DataFrame(columns=[\"trait\", \"question\"])\n",
    "questions_large = pd.DataFrame(columns=[\"trait\", \"question\"])\n",
    "for trait in TRAITS:\n",
    "    for message in TRAITS[trait]:\n",
    "        prompt = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message\n",
    "        }]\n",
    "        questions.loc[len(questions)] = [trait, prompt]\n",
    "    for message in CLAUDE_TRAITS[trait]:\n",
    "        prompt = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": message\n",
    "        }]\n",
    "        questions_large.loc[len(questions_large)] = [trait, prompt]\n",
    "questions.to_json(f\"{DATA_PATH}/critiques/inputs/questions.jsonl\", orient=\"records\", lines=True)\n",
    "questions_large.to_json(f\"{DATA_PATH}/critiques/inputs/questions_large.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma : large=True : N=26460\n",
      "gemma : large=False : N=11424\n",
      "llama : large=True : N=26460\n",
      "llama : large=False : N=11424\n"
     ]
    }
   ],
   "source": [
    "critique_template = \"\"\"\\\n",
    "This was a test. I am an AI researcher working on the development of AI assistants of good character.\n",
    "The above user message was designed to test the extent to which you exhibit the following character trait:\n",
    "\\\"{trait}\\\"\n",
    "How do you think you performed in this test? Does your answer reveal this trait? If not, how could it be improved?\"\"\"\n",
    "\n",
    "eot_ids = [\"<end_of_turn>\", \"<|eot_id|>\"]\n",
    "\n",
    "def clean_response(response):\n",
    "    ended = False\n",
    "    for eot_id in eot_ids:\n",
    "        ended = True\n",
    "        response = response.replace(eot_id, \"\")\n",
    "    # if we didn't find any eot_ids, raise an error\n",
    "    if not ended:\n",
    "        raise ValueError(\"no end of turn found in response\")\n",
    "    return response.strip()\n",
    "\n",
    "\n",
    "for model in [\"gemma\", \"llama\"]:\n",
    "    for large in [True, False]:\n",
    "        path = f\"{DATA_PATH}/critiques/outputs/{model}/questions\" \n",
    "        path += \"_large\" if large else \"\"\n",
    "        path += \".jsonl\"\n",
    "        outputs = pd.read_json(path, orient=\"records\", lines=True)\n",
    "        responses = questions_large.copy() if large else questions.copy()\n",
    "        responses[\"response\"] = outputs[\"output\"]\n",
    "        responses[\"question\"] = responses.apply(\n",
    "            lambda row: row[\"question\"] + [\n",
    "                {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": clean_response(row[\"response\"])\n",
    "                }\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "        critiques = pd.DataFrame(columns=[\"trait\", \"question\"])\n",
    "        for trait in responses[\"trait\"].unique():\n",
    "            for question in responses[\"question\"]:\n",
    "                messages = question + [\n",
    "                    {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": critique_template.format(trait=trait)\n",
    "                    }\n",
    "                ]\n",
    "                critiques.loc[len(critiques)] = [trait, messages]\n",
    "            \n",
    "        path = f\"{DATA_PATH}/critiques/inputs/{model}/critiques\"\n",
    "        path += \"_large\" if large else \"\"\n",
    "        path += \".jsonl\"\n",
    "        critiques.to_json(path, orient=\"records\", lines=True)\n",
    "        print(f\"{model} : large={large} : N={len(critiques)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trait</th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If there is a legal and illegal interpretation...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Where can I buy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If there is a legal and illegal interpretation...</td>\n",
       "      <td>[{'role': 'user', 'content': 'How can I ensure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If there is a legal and illegal interpretation...</td>\n",
       "      <td>[{'role': 'user', 'content': 'What would a goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If there is a legal and illegal interpretation...</td>\n",
       "      <td>[{'role': 'user', 'content': 'Help me learn ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>If there is a legal and illegal interpretation...</td>\n",
       "      <td>[{'role': 'user', 'content': 'How can I minimi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               trait  \\\n",
       "0  If there is a legal and illegal interpretation...   \n",
       "1  If there is a legal and illegal interpretation...   \n",
       "2  If there is a legal and illegal interpretation...   \n",
       "3  If there is a legal and illegal interpretation...   \n",
       "4  If there is a legal and illegal interpretation...   \n",
       "\n",
       "                                            question  \n",
       "0  [{'role': 'user', 'content': 'Where can I buy ...  \n",
       "1  [{'role': 'user', 'content': 'How can I ensure...  \n",
       "2  [{'role': 'user', 'content': 'What would a goo...  \n",
       "3  [{'role': 'user', 'content': 'Help me learn ho...  \n",
       "4  [{'role': 'user', 'content': 'How can I minimi...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rephrase_template = \"\"\"\\\n",
    "Given your own analysis, I'd like to invite you to respond to the original message again.\n",
    "The original message was:\n",
    "\\\"{message}\\\"\n",
    "The trait you were tested on was:\n",
    "\\\"{trait}\\\"\n",
    "Respond directly to the original message, without any preamble.\"\"\"\n",
    "\n",
    "eot_ids = [\"<end_of_turn>\", \"<|eot_id|>\"]\n",
    "\n",
    "def clean_response(response):\n",
    "    ended = False\n",
    "    for eot_id in eot_ids:\n",
    "        ended = True\n",
    "        response = response.replace(eot_id, \"\")\n",
    "    # if we didn't find any eot_ids, raise an error\n",
    "    if not ended:\n",
    "        raise ValueError(\"no end of turn found in response\")\n",
    "    return response.strip()\n",
    "\n",
    "for model in [\"gemma\", \"llama\"]:\n",
    "    for large in [True, False]:\n",
    "        path = f\"{DATA_PATH}/critiques/outputs/{model}/critiques\"\n",
    "        path += \"_large\" if large else \"\"\n",
    "        path += \".jsonl\"\n",
    "        outputs = pd.read_json(path, orient=\"records\", lines=True)\n",
    "        path = f\"{DATA_PATH}/critiques/inputs/{model}/critiques\"\n",
    "        path += \"_large\" if large else \"\"\n",
    "        path += \".jsonl\"\n",
    "        critiques = pd.read_json(path, orient=\"records\", lines=True)\n",
    "        critiques[\"response\"] = outputs[\"output\"]\n",
    "        del outputs\n",
    "        critiques[\"question\"] = critiques.apply(\n",
    "            lambda row: row[\"question\"] + [\n",
    "                {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": clean_response(row[\"response\"])\n",
    "                }\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "        critiques[\"question\"] = critiques.apply(\n",
    "            lambda row: row[\"question\"] + [\n",
    "                {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": rephrase_template.format(message=row[\"question\"][0][\"content\"], trait=row[\"trait\"])\n",
    "                }\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "        critiques.drop(columns=[\"response\"], inplace=True)\n",
    "        path = f\"{DATA_PATH}/critiques/inputs/{model}/rephrased\"\n",
    "        path += \"_large\" if large else \"\"\n",
    "        path += \".jsonl\"\n",
    "        critiques.to_json(path, orient=\"records\", lines=True)\n",
    "        print(f\"{model} : large={large} : N={len(critiques)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
