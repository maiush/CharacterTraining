{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.finetuning/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 14/14 [00:00<00:00, 265.75ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.51s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/maius/oasst_top1/commit/9725585ef47e874fb0d557e5cce6ea5034098179', commit_message='Upload dataset', commit_description='', oid='9725585ef47e874fb0d557e5cce6ea5034098179', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/maius/oasst_top1', endpoint='https://huggingface.co', repo_type='dataset', repo_id='maius/oasst_top1'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 1\n",
    "\n",
    "control_tks = {\n",
    "    \"user\": \"<|im_start|>user\\n\",\n",
    "    \"assistant\": \"<|im_end|>\\n<|im_start|>assistant\\n\",\n",
    "    \"end\": \"<|im_end|>\\n\"\n",
    "}\n",
    "def get_messages(text):\n",
    "    for tk in control_tks:\n",
    "        text = text.replace(control_tks[tk], \"@!@!@!\")\n",
    "    text = text.split(\"@!@!@!\")\n",
    "    prompt, response = text[1], text[2]\n",
    "    return [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response}\n",
    "    ]\n",
    "\n",
    "data = load_dataset(\"OpenAssistant/oasst_top1_2023-08-25\", cache_dir=\"/scratch/datasets\")\n",
    "all_messages = []\n",
    "for idx in range(len(data[\"train\"])):\n",
    "    all_messages.append(get_messages(data[\"train\"][idx][\"text\"]))\n",
    "for idx in range(len(data[\"test\"])):\n",
    "    all_messages.append(get_messages(data[\"test\"][idx][\"text\"]))\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data[\"messages\"] = all_messages\n",
    "dataset = Dataset.from_pandas(data)\n",
    "dataset.push_to_hub(\n",
    "    \"maius/oasst_top1\",\n",
    "    private=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 75/75 [00:00<00:00, 473.67ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:04<00:00,  4.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/maius/oasst2/commit/f210874bfa98e56342c5b928ea6249f31f522ac5', commit_message='Upload dataset', commit_description='', oid='f210874bfa98e56342c5b928ea6249f31f522ac5', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/maius/oasst2', endpoint='https://huggingface.co', repo_type='dataset', repo_id='maius/oasst2'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = load_dataset(\"OpenAssistant/oasst2\", cache_dir=\"/scratch/datasets\")\n",
    "\n",
    "# group messages by message_tree_id\n",
    "grouped_messages = {}\n",
    "for split in data.keys():\n",
    "    for row in data[split]:\n",
    "        tree_id = row[\"message_tree_id\"]\n",
    "        if tree_id not in grouped_messages:\n",
    "            grouped_messages[tree_id] = []\n",
    "        \n",
    "        # store relevant information for each message\n",
    "        grouped_messages[tree_id].append({\n",
    "            \"message_id\": row[\"message_id\"],\n",
    "            \"parent_id\": row[\"parent_id\"],\n",
    "            \"text\": row[\"text\"],\n",
    "            \"role\": row[\"role\"]\n",
    "        })\n",
    "\n",
    "# sort messages within each tree and convert to the desired format\n",
    "all_messages = []\n",
    "for tree_id, messages in grouped_messages.items():\n",
    "    def process_tree(chains):\n",
    "        current_chains = []\n",
    "        for chain in chains:\n",
    "            children = [msg for msg in messages if msg[\"parent_id\"] == chain[-1][\"message_id\"]]\n",
    "            if len(children) == 0: continue\n",
    "            role = \"prompter\" if chain[-1][\"role\"] == \"assistant\" else \"assistant\"\n",
    "            for child in children: \n",
    "                assert child[\"role\"] == role\n",
    "                current_chains.append(chain + [child])     \n",
    "        return process_tree(current_chains) if current_chains else chains\n",
    "                \n",
    "    roots = [[msg] for msg in messages if not msg[\"parent_id\"]]\n",
    "    assert len(roots) == 1\n",
    "    assert roots[0][-1][\"role\"] == \"prompter\"\n",
    "    # walk the tree\n",
    "    chains = process_tree(roots)\n",
    "    # split each possible assistant message to train on\n",
    "    chains_extended = []\n",
    "    for chain in chains:\n",
    "        for idx in range(len(chain)):\n",
    "            if chain[idx][\"role\"] == \"assistant\":\n",
    "                chains_extended.append(chain[:idx+1])\n",
    "    chains = chains_extended\n",
    "    # convert to messages format\n",
    "    formatted_messages = []\n",
    "    for chain in chains:\n",
    "        current_messages, role = [], \"user\"\n",
    "        for msg in chain:\n",
    "            current_messages.append({\"role\": role, \"content\": msg[\"text\"]})\n",
    "            role = \"assistant\" if role == \"user\" else \"user\"\n",
    "        formatted_messages.append(current_messages)\n",
    "    all_messages.extend(formatted_messages)\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data[\"messages\"] = all_messages\n",
    "dataset = Dataset.from_pandas(data)\n",
    "dataset.push_to_hub(\n",
    "    \"maius/oasst2\",\n",
    "    private=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
